# converter.py
# -*- coding: utf-8 -*-
"""
é€šç”¨è·¯å¾„è½¬æ¢ä¸å¯¼å‡ºè„šæœ¬ï¼ˆæ”¯æŒè¾“å…¥/è¾“å‡ºåæ ‡ç³» isaac/habitatï¼‰ï¼Œå¹¶å†™å‡ºç›®æ ‡ JSON ç»“æ„ï¼š
- scenes[*].scene_idï¼šæ²¿ç”¨æºæ–‡ä»¶
- trajectories[*].trajectory_idï¼šæ²¿ç”¨æºæ–‡ä»¶ï¼ˆæ— åˆ™é€€å› episode_idï¼‰
- points[*].orientationï¼šä»…åšåæ ‡ç³»è½¬æ¢ï¼›out=habitat -> {x,y,z,w}ï¼›out=isaac -> {w,x,y,z}
- samplesï¼šåŒä¸€ trajectory çš„æ‰€æœ‰æŒ‡ä»¤éƒ½ä¼šå„è‡ªç”Ÿæˆä¸€æ¡ sample
- camera_parametersï¼šå¯ç”± --camera-json æŒ‡å®šæ•°ç»„ï¼Œå¦åˆ™ç•™ç©º
- dataset_metadata.scene_sourceï¼šè¾“å…¥æ–‡ä»¶åï¼ˆä¾‹å¦‚ input.jsonï¼‰
- dataset_metadata.input_format / output_formatï¼šæ¥è‡ª --in-fmt / --out-fmt

ç”¨æ³•ç¤ºä¾‹ï¼š
  python converter.py --input input.json --output out.json --in-fmt isaac/habitat --out-fmt isaac/habitat --group-size 5 --tail keep
"""

import math
import json
import argparse
from typing import List, Tuple, Dict, Any
from pathlib import Path
from collections import defaultdict
import sys
import os
import importlib

# ================ ç¯å¢ƒä¸ä¾èµ– ================
# ç¡®ä¿å¯ä»¥ import utils.*
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.pure_pursuit_dynamic_ld import PurePursuitFollower2D
from utils.rotation_isaac2habitat import Isaac2HabitatConverter  # isaac->habitat å››å…ƒæ•°å˜æ¢ï¼ˆç»• Z -90Â°ï¼‰


# ================ åæ ‡ç³»è½¬æ¢ ================
# ä½ç½®ï¼šisaac -> habitat : [x,y,z] -> [x, z, -y]
#      habitat -> isaac : [x,y,z] -> [x, -z, y]
def convert_position_dict(pos: Dict[str, float], in_fmt: str, out_fmt: str) -> Dict[str, float]:
    x = float(pos.get("x", 0.0)); y = float(pos.get("y", 0.0)); z = float(pos.get("z", 0.0))
    if in_fmt == out_fmt:
        return {"x": x, "y": y, "z": z}
    if in_fmt == "isaac" and out_fmt == "habitat":
        return {"x": x, "y": z, "z": -y}
    if in_fmt == "habitat" and out_fmt == "isaac":
        return {"x": x, "y": -z, "z": y}
    raise ValueError(f"Unsupported format conversion: {in_fmt} -> {out_fmt}")

# æ—‹è½¬ï¼ˆä¿æŒå››å…ƒæ•°ï¼Œåšåæ ‡ç³»å˜æ¢ï¼›ä¸è½¬æ¬§æ‹‰ï¼Œä¸åšè§’åº¦ç¼©æ”¾ï¼‰
_conv_i2h = Isaac2HabitatConverter(angle_rad=-math.pi/2)  # isaac->habitat

def convert_rotation_wxyz_for_orientation(rot: Dict[str, float], in_fmt: str, out_fmt: str):
    """
    è¾“å…¥ rot ä¸ºå­—å…¸ {w,x,y,z}ï¼ˆin åæ ‡ç³»ï¼‰ï¼Œè¿”å› [w,x,y,z]ï¼ˆout åæ ‡ç³»ï¼‰ã€‚
    è¯´æ˜ï¼šhabitat->isaac ä¸å†é™„åŠ  +90Â°ï¼›ç›´æ¥é€ä¼ ï¼ˆåæ ‡ç³»æ—‹è½¬ç”±ä¸Šæ¸¸ä¿è¯ï¼‰ã€‚
    """
    w = float(rot.get("w", 1.0)); x = float(rot.get("x", 0.0))
    y = float(rot.get("y", 0.0)); z = float(rot.get("z", 0.0))

    if in_fmt == out_fmt:
        return [w, x, y, z]

    if in_fmt == "isaac" and out_fmt == "habitat":
        # ä½ çš„è½¬æ¢å™¨ï¼šè¾“å…¥ (w,x,y,z) -> è¾“å‡º (x,z,y,w)
        x2, z2, y2, w2 = _conv_i2h.convert((w, x, y, z))
        return [w2, x2, y2, z2]  # å›åˆ° wxyz

    if in_fmt == "habitat" and out_fmt == "isaac":
        # å»æ‰ +90Â°ï¼šç›´æ¥é€ä¼ 
        return [w, x, y, z]

    raise ValueError(f"Unsupported rotation conversion: {in_fmt} -> {out_fmt}")

def format_orientation(rot_wxyz, out_fmt: str) -> Dict[str, float]:
    """
    rot_wxyz: [w,x,y,z] ï¼ˆå·²ç»æ˜¯ out åæ ‡ç³»ä¸‹çš„å››å…ƒæ•°ï¼‰
    è¿”å›ç”¨äºè¾“å‡º JSON çš„ orientation å­—æ®µï¼š
      - habitat: {"x": x, "y": y, "z": z, "w": w}
      - isaac  : {"w": w, "x": x, "y": y, "z": z}
    """
    w, x, y, z = rot_wxyz
    if out_fmt == "habitat":
        return {"x": float(x), "y": float(y), "z": float(z), "w": float(w)}
    return {"w": float(w), "x": float(x), "y": float(y), "z": float(z)}

# ================ Pure Pursuit æ§åˆ¶ ================
def _normalize_angle(theta: float) -> float:
    return (theta + math.pi) % (2 * math.pi) - math.pi

def run_pure_pursuit(path: List[Tuple[float, float]],
                     init_pos: Tuple[float, float],
                     init_heading: float,
                     init_y: float = 0.0,
                     dt: float = 0.3,
                     max_steps: int = 500):
    follower = PurePursuitFollower2D(path, control_dt=dt)
    agent_pos = init_pos
    agent_heading = init_heading
    actions = []

    for _ in range(max_steps):
        vx, vyaw, done = follower.compute_control(agent_pos, agent_heading)

        # â€œè€ rotationâ€å››å…ƒæ•°ï¼ˆè¾“å…¥åæ ‡ç³»ï¼Œä»… yawï¼‰
        half = 0.5 * agent_heading
        qw = math.cos(half); qx = 0.0; qy = 0.0; qz = math.sin(half)

        actions.append({
            "vx": vx, "vy": 0.0, "vyaw": vyaw, "dt": dt,
            "pos": {"x": agent_pos[0], "y": agent_pos[1], "z": init_y},
            "rotation": {"w": qw, "x": qx, "y": qy, "z": qz},
        })

        dx = vx * dt * math.cos(agent_heading)
        dy = vx * dt * math.sin(agent_heading)
        agent_pos = (agent_pos[0] + dx, agent_pos[1] + dy)
        agent_heading = _normalize_angle(agent_heading + vyaw * dt)
        if done:
            break
    return actions

# ================ åˆ†ç»„ä¸º pointsï¼ˆorientation æ˜ å°„ï¼›actions ä¸ºæ§åˆ¶å‘é‡ï¼‰ ================
def group_actions_into_points(actions: List[Dict[str, Any]],
                              in_fmt: str,
                              out_fmt: str,
                              chunk_size: int = 5,
                              remainder: str = "keep"):
    """
    æ¯ä¸ª pointï¼š
      - positionï¼šç»„é¦–å¸§ä½ç½®ï¼ˆin->outï¼‰
      - orientationï¼šç»„é¦–å¸§â€œè€ rotationâ€ï¼ˆin->outï¼›habitatè¾“å‡ºç”¨xyzwï¼Œisaacè¾“å‡ºç”¨wxyzï¼‰
      - actionï¼š
          * point   : ä¸‹ä¸€ä¸ª point çš„é¦–å¸§åæ ‡ï¼ˆæœ€åä¸€ä¸ª point æ— â€œä¸‹ä¸€ä¸ªâ€æ—¶ç”¨è‡ªå·±çš„æœ€åä¸€å¸§ï¼‰
          * straight/smooth: [[vx,vy,vyaw,dt], ...]
    åˆ—è¡¨æœ«å°¾é¢å¤–è¿½åŠ ä¸€ä¸ªç‚¹ï¼š
      - {"point_id": "END", "position": è½¨è¿¹æœ€åä¸€å¸§ä½ç½®ï¼ˆin->outï¼‰}
    """
    if not actions:
        return []

    if chunk_size is None or chunk_size < 1:
        chunk_size = 1

    def _vec(a):
        return [float(a.get("vx", 0.0)),
                float(a.get("vy", 0.0)),
                float(a.get("vyaw", 0.0)),
                float(a.get("dt", 0.0))]

    n = len(actions)
    full_end = (n // chunk_size) * chunk_size
    leftover = actions[full_end:]

    # â€”â€” å…ˆåˆ‡æ®µï¼ˆæ¯æ®µ=ä¸€ä¸ª pointï¼‰
    segments: List[List[Dict[str, Any]]] = []
    for start in range(0, full_end, chunk_size):
        segments.append(actions[start:start + chunk_size])

    if leftover:
        if remainder == "keep":
            segments.append(leftover)
        elif remainder == "merge":
            if segments:
                segments[-1].extend(leftover)
            else:
                segments.append(leftover)
        elif remainder == "drop":
            pass
        elif remainder == "pad":
            padded = list(leftover)
            zeros_needed = chunk_size - len(leftover)
            if zeros_needed > 0:
                last = leftover[-1]
                zact = {"vx": 0.0, "vy": 0.0, "vyaw": 0.0, "dt": 0.0,
                        "pos": last.get("pos", {}), "rotation": last.get("rotation", {})}
                padded.extend([zact for _ in range(zeros_needed)])
            segments.append(padded)
        else:
            segments.append(leftover)

    # â€”â€” é¢„è®¡ç®—æ¯æ®µä¿¡æ¯
    chunks_info = []
    for seg in segments:
        if not seg:
            continue
        first = seg[0]
        last  = seg[-1]
        pos_first_out = convert_position_dict(first.get("pos", {}), in_fmt, out_fmt)
        rot_wxyz      = convert_rotation_wxyz_for_orientation(first.get("rotation", {}), in_fmt, out_fmt)
        pos_last_out  = convert_position_dict(last.get("pos", {}),  in_fmt, out_fmt)
        step_vecs     = [_vec(a) for a in seg]
        chunks_info.append({
            "pos_first": pos_first_out,
            "rot_wxyz":  rot_wxyz,
            "pos_last":  pos_last_out,
            "vecs":      step_vecs,
        })

    # â€”â€” ç”Ÿæˆæ™®é€š pointsï¼ˆå«â€œä¸‹ä¸€ç‚¹åæ ‡â€çš„æç¤ºï¼‰
    pts = []
    for i, info in enumerate(chunks_info):
        pos_curr = info["pos_first"]
        rot_wxyz = info["rot_wxyz"]
        vecs     = info["vecs"]

        # ä¸‹ä¸€ä¸ªç‚¹çš„é¦–å¸§åæ ‡ï¼›æœ€åä¸€ä¸ªç‚¹å›é€€åˆ°è‡ªå·±çš„æœ€åä¸€å¸§
        if i + 1 < len(chunks_info):
            next_pos = chunks_info[i + 1]["pos_first"]
        else:
            next_pos = info["pos_last"]

        pts.append({
            "point_id": i,
            "position": {"x": pos_curr["x"], "y": pos_curr["y"], "z": pos_curr["z"]},
            "orientation": format_orientation(rot_wxyz, out_fmt),
            "camera_images": [],
            "action": [
                {"type": "point",
                 "content": f"({next_pos['x']:.6f},{next_pos['y']:.6f},{next_pos['z']:.6f})"},
                {"type": "straight", "content": vecs},
                {"type": "smooth",   "content": vecs},
            ]
        })

    # â€”â€” è¿½åŠ ç»ˆç‚¹ç‚¹ï¼špoint_id="END"ï¼Œåªå­˜æ•´æ¡è½¨è¿¹çš„æœ€åä¸€å¸§ä½ç½®
    traj_last_out = convert_position_dict(actions[-1].get("pos", {}), in_fmt, out_fmt)
    pts.append({
        "point_id": "END",
        "position": {"x": traj_last_out["x"], "y": traj_last_out["y"], "z": traj_last_out["z"]}
    })

    return pts




# ================ æŒ‡ä»¤æ”¶é›† ================
def _collect_instructions(eps) -> List[str]:
    """ä»ä¸€ç»„ episode ä¸­æ”¶é›†å…¨éƒ¨ instruction æ–‡æœ¬ï¼Œå»é‡ä¿åºã€‚"""
    seen = set()
    result = []
    for ep in eps:
        instr = ep.get("instruction", None)
        # å¸¸è§æ ¼å¼ï¼š{"instruction_text": "..."}
        if isinstance(instr, dict):
            text = instr.get("instruction_text")
            if text and text not in seen:
                seen.add(text)
                result.append(text)
        # å…¼å®¹ï¼šç›´æ¥ç»™å­—ç¬¦ä¸²
        elif isinstance(instr, str):
            if instr and instr not in seen:
                seen.add(instr)
                result.append(instr)
        # å…¼å®¹ï¼šåˆ—è¡¨é‡Œæ”¾å­—ç¬¦ä¸²æˆ– dict
        elif isinstance(instr, list):
            for item in instr:
                if isinstance(item, str):
                    if item and item not in seen:
                        seen.add(item)
                        result.append(item)
                elif isinstance(item, dict):
                    t = item.get("instruction_text")
                    if t and t not in seen:
                        seen.add(t)
                        result.append(t)
    return result

# ================ Loader & åŠ¨ä½œç”Ÿæˆ ================
def load_vlnce_loader(in_fmt: str):
    if in_fmt == "isaac":
        mod = importlib.import_module("utils.path_extract_isaac")
    elif in_fmt == "habitat":
        mod = importlib.import_module("utils.path_extract_habitat")
    else:
        raise ValueError('in_fmt å¿…é¡»æ˜¯ "isaac" æˆ– "habitat"')
    if not hasattr(mod, "VLNCEPathLoader"):
        raise ImportError(f"{mod.__name__} ä¸­æœªæ‰¾åˆ° VLNCEPathLoader")
    return getattr(mod, "VLNCEPathLoader")

def generate_actions(dataset, input_path, in_fmt: str):
    Loader = load_vlnce_loader(in_fmt)
    loader = Loader(input_path)
    try:
        paths_dict = loader.get_all_paths_and_starts()
    except TypeError:
        paths_dict = loader.get_all_paths_and_starts()

    for ep in dataset.get("episodes", []):
        ep_id = ep.get("episode_id")
        if ep_id not in paths_dict:
            continue
        info = paths_dict[ep_id]
        path = info["path"]
        if "start_pos_2d" in info:
            init_pos = tuple(info["start_pos_2d"])
            init_y = float(info.get("start_pos", (0, 0, 0))[2])
        else:
            sx, sy, sz = info["start_pos"]
            init_pos = (sx, sy)
            init_y = sz
        init_heading = info["start_heading"]
        actions = run_pure_pursuit(path, init_pos, init_heading, init_y)
        ep["action"] = actions
    return dataset

# ================ è½¬ä¸ºç›®æ ‡ç»“æ„ï¼ˆscene_id/trajectory_id æ²¿ç”¨æºå€¼ï¼‰ ================
def convert_to_output(dataset, in_fmt: str, out_fmt: str,
                      chunk_size: int = 5, remainder: str = "keep",
                      camera_details: List[Dict[str, Any]] = None,
                      input_filename: str = ""):
    episodes = dataset.get("episodes", [])
    # ä»¥æº scene_id åŸå€¼åˆ†ç»„
    by_scene = defaultdict(lambda: defaultdict(list))
    for ep in episodes:
        scene_id_raw = str(ep.get("scene_id", "unknown_scene"))
        traj_id = str(ep.get("trajectory_id", ep.get("episode_id", "0")))
        by_scene[scene_id_raw][traj_id].append(ep)

    scenes_out = []
    total_traj = 0
    total_samples = 0

    for scene_id_raw in sorted(by_scene.keys()):
        trajectories_out = []
        for traj_id_raw, eps in sorted(by_scene[scene_id_raw].items(), key=lambda kv: kv[0]):
            base_ep = next((ep for ep in eps if ep.get("action")), eps[0])
            if not base_ep.get("action"):
                continue

            points = group_actions_into_points(
                base_ep["action"], in_fmt=in_fmt, out_fmt=out_fmt,
                chunk_size=chunk_size, remainder=remainder
            )

            # æ”¶é›†è¯¥ trajectory çš„å…¨éƒ¨æŒ‡ä»¤ï¼Œæ¯æ¡ç”Ÿæˆä¸€ä¸ª sample
            all_instrs = _collect_instructions(eps)
            samples_list = [
                {
                    "type": "vlnce",
                    "instruction": txt,
                    "memory_per_point": []   # å¯ç•™ç©º
                }
                for txt in all_instrs
            ]

            trajectories_out.append({
                "trajectory_id": str(traj_id_raw),  # ä¿ç•™è€ ID
                "points": points,
                "samples": samples_list
            })
            total_traj += 1
            total_samples += len(samples_list)

        scenes_out.append({
            "scene_id": scene_id_raw,      # ä¿ç•™æº scene_id
            "trajectories": trajectories_out
        })

    meta = {
        "name": "R2R",                               # å¦‚éœ€æ”¹åå¯åœ¨æ­¤å¤„è°ƒæ•´
        "scene_source": input_filename or "",        # âœ… ä½¿ç”¨è¾“å…¥æ–‡ä»¶å
        "input_format": in_fmt,                      # âœ… æ–°å¢
        "output_format": out_fmt,                    # âœ… æ–°å¢
        "num_scenes": len(scenes_out),
        "num_trajectories": total_traj,
        "num_samples": total_samples,
        "camera_parameters": {
            "camera_number": len(camera_details) if camera_details else 0,
            "camera_details": camera_details or []
        }
    }
    return {"dataset_metadata": meta, "scenes": scenes_out}

# ================ CLI ================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", required=True, help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--in-fmt", choices=["isaac", "habitat"], default="isaac",
                        help="è¾“å…¥åæ ‡ç³»ï¼ˆå†³å®šä½¿ç”¨å“ªä¸ª VLNCEPathLoaderï¼‰ã€‚é»˜è®¤ isaacã€‚")
    parser.add_argument("--out-fmt", choices=["isaac", "habitat"], default="isaac",
                        help="è¾“å‡ºåæ ‡ç³»ï¼ˆpoints çš„ position/orientationï¼‰ã€‚é»˜è®¤ isaacã€‚")
    parser.add_argument("--group-size", type=int, default=None,
                        help="æ¯ä¸ª point æ‰“åŒ…çš„åŠ¨ä½œæ•°ï¼ˆ>=1ï¼‰ã€‚ä¸å¡«åˆ™äº¤äº’è¾“å…¥ï¼Œé»˜è®¤ 5ã€‚")
    parser.add_argument("--tail", choices=["keep", "merge", "drop", "pad"], default="keep",
                        help="æœ€åä¸è¶³ä¸€ç»„çš„å¤„ç†ç­–ç•¥ã€‚é»˜è®¤ keepã€‚")
    parser.add_argument("--camera-json", type=str, default=None,
                        help="å¯é€‰ï¼šç›¸æœºè¯¦æƒ… JSON æ–‡ä»¶è·¯å¾„ï¼ˆæ•°ç»„ï¼‰ã€‚ä¸æä¾›åˆ™ camera_details ç•™ç©ºã€‚")
    args = parser.parse_args()

    # group-size
    if args.group_size is None:
        try:
            s = input("æ¯ä¸ª point æ‰“åŒ…å¤šå°‘ä¸ª actionï¼Ÿ(é»˜è®¤ 5): ").strip()
            group_size = int(s) if s else 5
        except Exception:
            group_size = 5
    else:
        group_size = args.group_size
    if group_size < 1:
        print("âš ï¸ group-size å¿…é¡» >= 1ï¼Œå·²æ”¹ä¸º 1")
        group_size = 1

    input_path = Path(args.input)
    output_path = Path(args.output)

    dataset = json.loads(input_path.read_text(encoding="utf-8"))

    # å¯é€‰ç›¸æœºè¯¦æƒ…
    camera_details = None
    if args.camera_json:
        try:
            camera_details = json.loads(Path(args.camera_json).read_text(encoding="utf-8"))
            if not isinstance(camera_details, list):
                print("âš ï¸ --camera-json å†…å®¹åº”ä¸ºæ•°ç»„ï¼Œå·²å¿½ç•¥ã€‚")
                camera_details = None
        except Exception as e:
            print(f"âš ï¸ è¯»å– --camera-json å¤±è´¥ï¼š{e}ï¼Œå°†ç•™ç©ºã€‚")
            camera_details = None

    print(f"ğŸš€ è¿è¡Œ & è½¬æ¢ï¼ˆin={args.in_fmt} â†’ out={args.out_fmt}ï¼›group-size={group_size}ï¼›tail={args.tail}ï¼‰...")
    dataset_with_actions = generate_actions(dataset, str(input_path), in_fmt=args.in_fmt)
    out_json = convert_to_output(dataset_with_actions,
                                 in_fmt=args.in_fmt, out_fmt=args.out_fmt,
                                 chunk_size=group_size, remainder=args.tail,
                                 camera_details=camera_details,
                                 input_filename=input_path.name)   # âœ… ä¼ å…¥è¾“å…¥æ–‡ä»¶å

    output_path.write_text(json.dumps(out_json, indent=2, ensure_ascii=False), encoding="utf-8")
    print(f"âœ… è¾“å‡ºå·²ä¿å­˜è‡³ï¼š{args.output}")
